---
phase: 58-agent-sdk-adapter
plan: 02
type: execute
wave: 2
depends_on: ["58-01"]
files_modified:
  - backend/tests/unit/llm/test_claude_agent_adapter.py
  - backend/tests/unit/test_ai_service_agent.py
autonomous: true

must_haves:
  truths:
    - "Unit tests verify SDK event translation to StreamChunk for all event types"
    - "Unit tests verify AIService agent provider detection and routing"
    - "Unit tests verify tool activity indicator generation from tool_use chunks"
    - "Unit tests verify source attribution data propagation in complete chunks"
    - "Unit tests verify error handling with diagnostic info"
    - "All existing LLM adapter tests still pass (zero regressions)"
  artifacts:
    - path: "backend/tests/unit/llm/test_claude_agent_adapter.py"
      provides: "Comprehensive unit tests for ClaudeAgentAdapter.stream_chat()"
      min_lines: 150
    - path: "backend/tests/unit/test_ai_service_agent.py"
      provides: "Unit tests for AIService agent provider routing"
      min_lines: 80
  key_links:
    - from: "backend/tests/unit/llm/test_claude_agent_adapter.py"
      to: "backend/app/services/llm/claude_agent_adapter.py"
      via: "imports and mock-based testing"
      pattern: "ClaudeAgentAdapter|mock.*query"
    - from: "backend/tests/unit/test_ai_service_agent.py"
      to: "backend/app/services/ai_service.py"
      via: "imports and mock-based testing"
      pattern: "AIService|is_agent_provider|_stream_agent_chat"
---

<objective>
Add comprehensive unit tests for ClaudeAgentAdapter stream_chat implementation and AIService agent provider routing.

Purpose: Verify that SDK event translation, MCP tool integration, error handling, and AIService routing work correctly through isolated unit tests. Tests must mock the SDK to avoid requiring API keys or network access.

Output: Two test files covering the complete adapter and service integration surface area, with all existing tests still passing.
</objective>

<execution_context>
@/Users/a1testingmac/.claude/get-shit-done/workflows/execute-plan.md
@/Users/a1testingmac/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Plan 01 summary (provides the implementation being tested)
@.planning/phases/58-agent-sdk-adapter/58-01-SUMMARY.md

# Existing test patterns
@backend/tests/unit/llm/test_claude_agent_adapter.py
@backend/tests/unit/llm/test_claude_cli_adapter.py

# Implementation files being tested
@backend/app/services/llm/claude_agent_adapter.py
@backend/app/services/ai_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update ClaudeAgentAdapter unit tests for stream_chat implementation</name>
  <files>
    backend/tests/unit/llm/test_claude_agent_adapter.py
  </files>
  <action>
    Replace the existing stub tests with comprehensive tests for the working stream_chat implementation.
    Keep the existing init/provider/factory tests (they still apply). Add new test classes for stream_chat.

    **Mock strategy:** Mock `claude_agent_sdk.query` at the import location in claude_agent_adapter.py
    using `@patch('app.services.llm.claude_agent_adapter.query')`. Create mock message objects that
    simulate SDK event types.

    **Test classes to create:**

    **TestClaudeAgentAdapterStreamChat:**

    1. `test_text_streaming_via_stream_event` — Mock query() to yield a StreamEvent with delta.text.
       Verify StreamChunk(chunk_type="text", content="hello") is yielded. This tests the primary
       streaming path (incremental text via StreamEvent).

    2. `test_tool_use_visibility` — Mock query() to yield an AssistantMessage with a ToolUseBlock.
       Verify StreamChunk(chunk_type="tool_use", tool_call={"id": ..., "name": "mcp__ba__search_documents", "input": ...})
       is yielded. This tests tool activity indicator support.

    3. `test_complete_with_usage` — Mock query() to yield a ResultMessage with usage stats.
       Verify StreamChunk(chunk_type="complete", usage={"input_tokens": 100, "output_tokens": 50})
       is yielded.

    4. `test_complete_with_documents_used` — Mock query() to yield a ResultMessage. Set
       _documents_used_context before calling. Verify the complete chunk's metadata contains
       documents_used list.

    5. `test_artifact_created_detection` — Mock query() to yield an AssistantMessage with a
       ToolResultBlock containing "ARTIFACT_CREATED:{...}|" marker. Verify StreamChunk with
       metadata containing artifact_created event data is yielded.

    6. `test_error_handling` — Mock query() to raise an exception. Verify StreamChunk(chunk_type="error",
       error="Agent SDK error...") is yielded with diagnostic info.

    7. `test_multi_turn_text_continuity` — Mock query() to yield multiple StreamEvents across
       simulated agent turns. Verify all text chunks are yielded in order (continuous stream —
       locked decision).

    8. `test_text_block_not_duplicated` — Mock query() to yield a StreamEvent with text followed
       by an AssistantMessage with the same TextBlock. Verify only one text chunk is yielded
       (StreamEvent handles text when include_partial_messages=True, TextBlock is skipped).

    9. `test_convert_messages_to_prompt` — Test the _convert_messages_to_prompt helper directly.
       Verify message list converts to "[USER]: content\n\n[ASSISTANT]: content" format.

    10. `test_context_vars_set_before_query` — Mock query() and verify that ContextVars are set
        with the correct db/project_id/thread_id values before query() is called.

    **TestClaudeAgentAdapterInit (keep existing + extend):**

    11. Keep existing init tests (api_key, default_model, custom_model, provider)
    12. Add: `test_mcp_server_created` — Verify mcp_server attribute is not None after init
    13. Add: `test_is_agent_provider` — Verify `is_agent_provider` is True
    14. Add: `test_set_context` — Verify set_context stores db/project_id/thread_id

    **TestClaudeAgentAdapterFactory (keep existing):**
    Keep all 3 existing factory tests.

    **Mock object helpers:** Create helper functions at module level:
    - `make_stream_event(text)` — Creates mock StreamEvent with delta.text
    - `make_assistant_message(blocks)` — Creates mock AssistantMessage with content blocks
    - `make_result_message(input_tokens, output_tokens)` — Creates mock ResultMessage with usage
    - `make_text_block(text)` — Creates mock TextBlock
    - `make_tool_use_block(id, name, input)` — Creates mock ToolUseBlock
    - `make_tool_result_block(content)` — Creates mock ToolResultBlock

    **Important patterns:**
    - Use `async for chunk in adapter.stream_chat(...)` to collect all StreamChunks
    - Mock `create_ba_mcp_server` to avoid real MCP server creation in tests
    - Use `@patch` decorators for ContextVars if needed to verify they're set
    - All tests must be async (use `@pytest.mark.asyncio`)
  </action>
  <verify>
    Run: `cd /Users/a1testingmac/projects/XtraSkill/backend && python -m pytest tests/unit/llm/test_claude_agent_adapter.py -v` — all tests pass.

    Run: `cd /Users/a1testingmac/projects/XtraSkill/backend && python -m pytest tests/unit/llm/ -v` — all LLM adapter tests pass (zero regressions).
  </verify>
  <done>
    ClaudeAgentAdapter has 15+ unit tests covering:
    - Text streaming via StreamEvent (incremental)
    - Tool use visibility (ToolUseBlock -> tool_use chunk)
    - Complete with usage stats
    - Source attribution via documents_used
    - Artifact created detection from ToolResultBlock
    - Error handling with diagnostic info
    - Multi-turn text continuity
    - No text duplication (StreamEvent + TextBlock)
    - Message-to-prompt conversion
    - Context variable propagation
    - MCP server creation
    - is_agent_provider attribute
    - All existing init/factory tests still pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Add AIService agent routing unit tests</name>
  <files>
    backend/tests/unit/test_ai_service_agent.py
  </files>
  <action>
    Create a new test file for AIService agent provider routing. This tests the _stream_agent_chat
    path specifically, verifying that agent providers bypass the manual tool loop.

    **Mock strategy:** Mock `LLMFactory.create` to return a mock adapter with `is_agent_provider=True`
    and a controllable `stream_chat` async generator.

    **Test class: TestAIServiceAgentRouting:**

    1. `test_agent_provider_detected` — Create AIService with mock agent adapter. Verify
       `svc.is_agent_provider` is True.

    2. `test_direct_api_provider_not_agent` — Create AIService with mock direct adapter. Verify
       `svc.is_agent_provider` is False.

    3. `test_agent_streams_text_as_sse` — Mock adapter.stream_chat to yield
       StreamChunk(chunk_type="text", content="hello"). Call AIService.stream_chat and verify
       it yields `{"event": "text_delta", "data": '{"text": "hello"}'}`.

    4. `test_agent_tool_use_yields_tool_executing` — Mock adapter.stream_chat to yield
       StreamChunk(chunk_type="tool_use", tool_call={"name": "mcp__ba__search_documents", ...}).
       Verify AIService yields `{"event": "tool_executing", "data": '{"status": "Searching project documents..."}'}`.

    5. `test_agent_save_artifact_tool_status` — Mock adapter.stream_chat to yield tool_use for
       save_artifact. Verify status message is "Generating artifact...".

    6. `test_agent_complete_with_documents_used` — Mock adapter to yield complete chunk with
       metadata containing documents_used. Verify AIService includes documents_used in
       message_complete event data.

    7. `test_agent_error_forwarded` — Mock adapter to yield error chunk. Verify AIService yields
       error SSE event.

    8. `test_agent_artifact_created_event` — Mock adapter to yield chunk with artifact_created
       in metadata. Verify AIService yields artifact_created SSE event.

    9. `test_agent_no_manual_tool_execution` — Mock adapter to yield tool_use chunk. Verify
       AIService does NOT call execute_tool (the method that runs tools manually for direct API).

    10. `test_agent_context_set_on_adapter` — Verify AIService calls adapter.set_context(db,
        project_id, thread_id) before streaming.

    **Helper function:**
    - `async_gen(*chunks)` — Creates an async generator that yields the provided StreamChunk objects.
      This makes it easy to mock adapter.stream_chat.

    **Mock patterns:**
    - `@patch('app.services.ai_service.LLMFactory')` to control adapter creation
    - `MagicMock(is_agent_provider=True)` for adapter attributes
    - `AsyncMock` for async methods where needed
    - All tests must be async
  </action>
  <verify>
    Run: `cd /Users/a1testingmac/projects/XtraSkill/backend && python -m pytest tests/unit/test_ai_service_agent.py -v` — all tests pass.

    Run: `cd /Users/a1testingmac/projects/XtraSkill/backend && python -m pytest tests/unit/ -v --ignore=tests/unit/frontend` — all unit tests pass (zero regressions).
  </verify>
  <done>
    AIService agent routing has 10 unit tests covering:
    - Agent provider detection (True for agent adapters, False for direct API)
    - Text StreamChunk -> text_delta SSE event translation
    - Tool use -> tool_executing with correct status messages
    - Complete -> message_complete with documents_used for source attribution
    - Error -> error SSE event forwarding
    - Artifact created event propagation
    - No manual tool execution for agent providers
    - Context set on adapter before streaming
    - All existing unit tests pass with zero regressions
  </done>
</task>

</tasks>

<verification>
1. All adapter tests pass: `python -m pytest tests/unit/llm/test_claude_agent_adapter.py -v`
2. All AI service tests pass: `python -m pytest tests/unit/test_ai_service_agent.py -v`
3. Full LLM test suite passes: `python -m pytest tests/unit/llm/ -v`
4. Full unit test suite passes: `python -m pytest tests/unit/ -v --ignore=tests/unit/frontend`
5. No regressions in existing tests
</verification>

<success_criteria>
1. ClaudeAgentAdapter has 15+ tests covering all SDK event translation paths
2. AIService agent routing has 10 tests covering SSE event generation and tool loop bypass
3. All test mocks properly isolate from real SDK (no API key required)
4. Zero regressions in existing test suite
5. Tests verify locked decisions: tool activity indicators, source attribution, error diagnostics, no turn limits
</success_criteria>

<output>
After completion, create `.planning/phases/58-agent-sdk-adapter/58-02-SUMMARY.md`
</output>
