---
phase: 04-artifact-generation-export
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models.py
  - backend/app/services/ai_service.py
  - backend/app/routes/artifacts.py
  - backend/main.py
autonomous: true

must_haves:
  truths:
    - "Artifact model exists in database schema"
    - "Claude uses save_artifact tool to generate user stories"
    - "Claude uses save_artifact tool to generate acceptance criteria"
    - "Claude uses save_artifact tool to generate requirements documents"
    - "Generated artifacts persist in database"
    - "Artifacts are associated with thread"
    - "Artifact creation emits SSE event for frontend"
  artifacts:
    - path: "backend/app/models.py"
      provides: "Artifact model with ArtifactType enum"
      contains: "class Artifact"
    - path: "backend/app/services/ai_service.py"
      provides: "SAVE_ARTIFACT_TOOL definition and execution"
      contains: "save_artifact"
    - path: "backend/app/routes/artifacts.py"
      provides: "GET list, GET detail endpoints"
      exports: ["router"]
  key_links:
    - from: "backend/app/services/ai_service.py"
      to: "backend/app/models.py"
      via: "Artifact model for tool execution"
      pattern: "from app.models import.*Artifact"
    - from: "backend/app/routes/artifacts.py"
      to: "backend/app/models.py"
      via: "Artifact model usage"
      pattern: "from app.models import.*Artifact"
---

<objective>
Create backend artifact model and extend ai_service.py with save_artifact tool for Agent SDK-based generation.

Purpose: Enable Claude to autonomously generate structured business analysis artifacts during conversations using the existing tool execution pattern from Phase 3.

Output: Artifact database model, save_artifact tool in ai_service.py, and API endpoints for list/get operations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-artifact-generation-export/04-RESEARCH.md

# Existing patterns
@backend/app/models.py
@backend/app/routes/conversations.py
@backend/app/services/ai_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Artifact model to database</name>
  <files>backend/app/models.py</files>
  <action>
Add ArtifactType enum and Artifact model to models.py following existing patterns:

```python
class ArtifactType(str, PyEnum):
    """Types of generated artifacts."""
    USER_STORIES = "user_stories"
    ACCEPTANCE_CRITERIA = "acceptance_criteria"
    REQUIREMENTS_DOC = "requirements_doc"

class Artifact(Base):
    """Generated business analysis artifact from conversation."""

    __tablename__ = "artifacts"

    id: Mapped[str] = mapped_column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    thread_id: Mapped[str] = mapped_column(String(36), ForeignKey("threads.id", ondelete="CASCADE"), nullable=False, index=True)
    artifact_type: Mapped[ArtifactType] = mapped_column(Enum(ArtifactType, native_enum=False, length=30), nullable=False)
    title: Mapped[str] = mapped_column(String(255), nullable=False)
    content_markdown: Mapped[str] = mapped_column(Text, nullable=False)
    content_json: Mapped[Optional[str]] = mapped_column(Text, nullable=True)  # Structured data for programmatic access
    created_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), default=datetime.utcnow, nullable=False)

    thread: Mapped["Thread"] = relationship(back_populates="artifacts")
```

Add artifacts relationship to Thread model:
```python
artifacts: Mapped[List["Artifact"]] = relationship(
    back_populates="thread",
    cascade="all, delete-orphan",
    passive_deletes=True,
    order_by="Artifact.created_at.desc()"
)
```

Run database migration after adding model.
  </action>
  <verify>
```bash
cd backend && python -c "from app.models import Artifact, ArtifactType; print('Model imports OK')"
cd backend && python -c "from app.database import engine; from app.models import Base; import asyncio; asyncio.run(Base.metadata.create_all(engine.sync_engine) if hasattr(engine, 'sync_engine') else print('async engine'))"
```
  </verify>
  <done>Artifact model with ArtifactType enum exists, Thread has artifacts relationship, database table created</done>
</task>

<task type="auto">
  <name>Task 2: Extend ai_service.py with save_artifact tool</name>
  <files>backend/app/services/ai_service.py</files>
  <action>
Extend existing ai_service.py with SAVE_ARTIFACT_TOOL following the search_documents pattern:

1. Add import for Artifact model:
   ```python
   from app.models import Artifact, ArtifactType
   ```

2. Define SAVE_ARTIFACT_TOOL after DOCUMENT_SEARCH_TOOL:
   ```python
   SAVE_ARTIFACT_TOOL = {
       "name": "save_artifact",
       "description": """Save a business analysis artifact to the current conversation thread.

   USE THIS TOOL WHEN:
   - User requests user stories, acceptance criteria, or requirements documents
   - You have gathered enough context from conversation and documents
   - User asks to "create", "generate", "write", or "document" requirements

   BEFORE USING:
   - Consider using search_documents first to gather project context
   - Review the full conversation for ALL requirements discussed
   - Ensure comprehensive coverage, not just recent messages

   You may call this tool multiple times to create multiple artifacts.""",
       "input_schema": {
           "type": "object",
           "properties": {
               "artifact_type": {
                   "type": "string",
                   "enum": ["user_stories", "acceptance_criteria", "requirements_doc"],
                   "description": "Type: user_stories (Given/When/Then), acceptance_criteria (testable checklist), requirements_doc (IEEE 830-style)"
               },
               "title": {
                   "type": "string",
                   "description": "Descriptive title, e.g., 'Login Feature - User Stories'"
               },
               "content_markdown": {
                   "type": "string",
                   "description": "Full artifact content in markdown with proper headers and formatting"
               }
           },
           "required": ["artifact_type", "title", "content_markdown"]
       }
   }
   ```

3. Add save_artifact to self.tools list in __init__

4. Update execute_tool to handle save_artifact:
   ```python
   async def execute_tool(self, tool_name: str, tool_input: dict, project_id: str, thread_id: str, db) -> str:
       if tool_name == "save_artifact":
           artifact = Artifact(
               thread_id=thread_id,
               artifact_type=ArtifactType(tool_input["artifact_type"]),
               title=tool_input["title"],
               content_markdown=tool_input["content_markdown"]
           )
           db.add(artifact)
           await db.commit()
           await db.refresh(artifact)
           return f"Artifact saved successfully: '{artifact.title}' (ID: {artifact.id}). User can now export as PDF, Word, or Markdown from the artifacts list."

       elif tool_name == "search_documents":
           # existing logic...
   ```

5. Update stream_chat to pass thread_id to execute_tool and emit artifact_created event:
   - Add thread_id parameter to stream_chat signature
   - When save_artifact executes, yield artifact_created event with artifact details

6. Update SYSTEM_PROMPT to mention artifact generation capability:
   Add: "5. GENERATE ARTIFACTS: When users request documentation (user stories, acceptance criteria, requirements docs), use the save_artifact tool to create professional deliverables."

7. Update conversations.py route to pass thread_id to stream_chat
  </action>
  <verify>
```bash
cd backend && python -c "from app.services.ai_service import AIService, SAVE_ARTIFACT_TOOL; print(f'Tool: {SAVE_ARTIFACT_TOOL[\"name\"]}')"
cd backend && python -c "from app.services.ai_service import AIService; s = AIService(); print(f'Tools: {[t[\"name\"] for t in s.tools]}')"
```
  </verify>
  <done>ai_service.py has SAVE_ARTIFACT_TOOL, execute_tool handles save_artifact, stream_chat emits artifact_created events</done>
</task>

<task type="auto">
  <name>Task 3: Create artifacts API endpoints (GET only)</name>
  <files>backend/app/routes/artifacts.py, backend/main.py</files>
  <action>
Create artifacts.py router with GET endpoints only (generation happens via chat with save_artifact tool):

```python
from datetime import datetime
from typing import List
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.database import get_db
from app.models import Artifact, Thread, Project, ArtifactType
from app.routes.auth import get_current_user

router = APIRouter()

class ArtifactResponse(BaseModel):
    id: str
    thread_id: str
    artifact_type: ArtifactType
    title: str
    content_markdown: str
    created_at: datetime

    class Config:
        from_attributes = True
```

1. GET /threads/{thread_id}/artifacts - List artifacts for thread
   ```python
   @router.get("/threads/{thread_id}/artifacts", response_model=List[ArtifactResponse])
   async def list_thread_artifacts(
       thread_id: str,
       current_user: dict = Depends(get_current_user),
       db: AsyncSession = Depends(get_db)
   ):
       # Validate thread access
       stmt = (
           select(Thread)
           .where(Thread.id == thread_id)
           .options(selectinload(Thread.project))
       )
       result = await db.execute(stmt)
       thread = result.scalar_one_or_none()

       if not thread or thread.project.user_id != current_user["user_id"]:
           raise HTTPException(status_code=404, detail="Thread not found")

       # Get artifacts
       stmt = (
           select(Artifact)
           .where(Artifact.thread_id == thread_id)
           .order_by(Artifact.created_at.desc())
       )
       result = await db.execute(stmt)
       return result.scalars().all()
   ```

2. GET /artifacts/{artifact_id} - Get single artifact
   ```python
   @router.get("/artifacts/{artifact_id}", response_model=ArtifactResponse)
   async def get_artifact(
       artifact_id: str,
       current_user: dict = Depends(get_current_user),
       db: AsyncSession = Depends(get_db)
   ):
       stmt = (
           select(Artifact)
           .where(Artifact.id == artifact_id)
           .options(selectinload(Artifact.thread).selectinload(Thread.project))
       )
       result = await db.execute(stmt)
       artifact = result.scalar_one_or_none()

       if not artifact or artifact.thread.project.user_id != current_user["user_id"]:
           raise HTTPException(status_code=404, detail="Artifact not found")

       return artifact
   ```

Register router in main.py:
```python
from app.routes.artifacts import router as artifacts_router
app.include_router(artifacts_router, prefix="/api", tags=["artifacts"])
```

Note: No POST endpoint needed - artifact generation happens through the existing chat endpoint when Claude uses the save_artifact tool.
  </action>
  <verify>
```bash
cd backend && python -c "from app.routes.artifacts import router; print(f'Routes: {[r.path for r in router.routes]}')"
cd backend && python -c "from main import app; print('App imports OK')"
```
Test endpoint:
```bash
curl http://localhost:8000/api/threads/test-id/artifacts -H "Authorization: Bearer $TOKEN"
# Should return 404 (thread not found) or 401 (no token) - confirms route registered
```
  </verify>
  <done>Artifacts router registered with GET list and GET detail endpoints, auth working</done>
</task>

</tasks>

<verification>
1. Artifact model imports without errors
2. ArtifactType enum has three values (user_stories, acceptance_criteria, requirements_doc)
3. Thread model has artifacts relationship
4. SAVE_ARTIFACT_TOOL defined in ai_service.py
5. AIService.tools includes save_artifact
6. execute_tool handles save_artifact and persists to database
7. stream_chat emits artifact_created event when tool executes
8. Artifacts router has two GET endpoints (list, detail)
9. Router registered in main.py
</verification>

<success_criteria>
- Artifact database model persists with thread relationship
- Claude autonomously uses save_artifact tool when user requests artifacts
- Claude can search documents before generating artifacts for better context
- Artifact creation emits SSE event for frontend notification
- API endpoints handle list and get operations with proper auth
- Existing chat flow unchanged - generation is just another tool execution
</success_criteria>

<output>
After completion, create `.planning/phases/04-artifact-generation-export/04-01-SUMMARY.md`
</output>
