# Requirements: v1.8 LLM Provider Switching (Archived)

**Defined:** 2026-01-31
**Completed:** 2026-01-31
**Status:** All v1.8 requirements delivered

## v1.8 Requirements â€” COMPLETED

All requirements from this milestone have been validated and shipped.

### Settings

- [x] **SET-01**: User can select default LLM provider in Settings (Claude/Gemini/DeepSeek)
- [x] **SET-02**: Provider selection persists across sessions via SharedPreferences

### Conversation Binding

- [x] **CONV-01**: New conversations use the currently selected default provider
- [x] **CONV-02**: Thread database stores `model_provider` column
- [x] **CONV-03**: Returning to existing conversation uses its stored model (not current default)

### UI Indicators

- [x] **UI-01**: Model indicator displays below chat window showing provider name
- [x] **UI-02**: Indicator uses provider-specific color accent (visual differentiation)

### Backend Integration

- [x] **BACK-01**: Adapter pattern abstracts provider API differences
- [x] **BACK-02**: Anthropic adapter extracted from current implementation
- [x] **BACK-03**: Gemini adapter using `google-genai` SDK with streaming
- [x] **BACK-04**: DeepSeek adapter using OpenAI SDK with `base_url` override
- [x] **BACK-05**: SSE heartbeats prevent timeout during extended thinking (5+ min)
- [x] **BACK-06**: StreamChunk normalizes response format across providers

## Deferred to v2.0

These requirements were identified but not in scope for v1.8:

### Provider Enhancements

- **PROV-01**: Cost indicator showing relative pricing per provider
- **PROV-02**: Capability tags showing what each provider supports
- **PROV-03**: Auto-fallback when primary provider fails or rate-limits
- **PROV-04**: User-configurable API keys in Settings UI

### Advanced Features

- **ADV-01**: DeepSeek reasoning content displayed in expandable UI section
- **ADV-02**: Per-project default provider (override global setting)
- **ADV-03**: Provider usage analytics and cost tracking

## Out of Scope

Explicitly excluded from all future versions unless strong user demand:

| Feature | Reason |
|---------|--------|
| Mid-conversation provider switching | Breaks conversation context and coherence |
| Custom model parameters per provider | Complexity; use sensible defaults |
| Local/self-hosted LLM support | Infrastructure complexity |
| Provider-specific prompt optimization | Maintain single BA skill prompt |
| Real-time pricing API integration | Overkill for cost optimization goal |

## Traceability Summary

| Requirement | Phase | Outcome |
|-------------|-------|---------|
| SET-01 | Phase 22 | Validated |
| SET-02 | Phase 22 | Validated |
| CONV-01 | Phase 22 | Validated |
| CONV-02 | Phase 20 | Validated |
| CONV-03 | Phase 22 | Validated |
| UI-01 | Phase 22 | Validated |
| UI-02 | Phase 22 | Validated |
| BACK-01 | Phase 19 | Validated |
| BACK-02 | Phase 19 | Validated |
| BACK-03 | Phase 21 | Validated |
| BACK-04 | Phase 21 | Validated |
| BACK-05 | Phase 20 | Validated |
| BACK-06 | Phase 19 | Validated |

**Final Coverage:** 13/13 requirements delivered (100%)

---
*Requirements defined: 2026-01-31*
*Milestone completed: 2026-01-31*
*Archived: 2026-02-01*
