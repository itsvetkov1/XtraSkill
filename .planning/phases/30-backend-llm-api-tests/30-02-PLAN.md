---
phase: 30-backend-llm-api-tests
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/fixtures/sse_helpers.py
  - backend/tests/unit/services/test_sse_streaming.py
  - backend/tests/unit/services/test_document_search.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "SSE helper can parse server-sent events from async stream"
    - "SSE helper can verify chunk sequences (text_delta -> message_complete)"
    - "FTS5 tests verify BM25 ranking orders results by relevance"
    - "FTS5 tests verify snippet highlighting with match markers"
    - "FTS5 tests verify empty result handling"
  artifacts:
    - path: "backend/tests/fixtures/sse_helpers.py"
      provides: "SSE parsing test utilities"
      min_lines: 30
    - path: "backend/tests/unit/services/test_sse_streaming.py"
      provides: "SSE streaming tests"
      min_lines: 40
    - path: "backend/tests/unit/services/test_document_search.py"
      provides: "FTS5 search tests (expanded)"
      contains: "TestSearchDocumentsRanking"
  key_links:
    - from: "backend/tests/fixtures/sse_helpers.py"
      to: "json.loads"
      via: "parse_sse_event"
      pattern: "json\\.loads"
    - from: "backend/tests/unit/services/test_document_search.py"
      to: "search_documents"
      via: "import"
      pattern: "from app.services.document_search import.*search_documents"
---

<objective>
Implement SSE streaming test helper and expand FTS5 document search tests

Purpose: Provide utilities for testing SSE endpoints (BLLM-04) and ensure comprehensive FTS5 search coverage including ranking, highlighting, and edge cases (BLLM-05)

Output: SSE helper fixture module and expanded document search tests
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/30-backend-llm-api-tests/30-RESEARCH.md
@backend/tests/fixtures/__init__.py
@backend/tests/unit/services/test_document_search.py
@backend/app/services/document_search.py
@backend/app/services/ai_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SSE test helper module</name>
  <files>backend/tests/fixtures/sse_helpers.py</files>
  <action>
Create `backend/tests/fixtures/sse_helpers.py` with utilities for testing SSE endpoints.

The helper should provide:

1. **parse_sse_line(line: str) -> dict**: Parse a single SSE line into event dict
   - Handle `event:` lines
   - Handle `data:` lines (JSON parse the data)
   - Handle comment lines (`: heartbeat`)
   - Return structured dict or None for empty lines

2. **collect_sse_events(response) -> List[dict]**: Async function to collect all SSE events from httpx streaming response
   - Use `response.aiter_lines()`
   - Buffer multi-line events
   - Return list of parsed events

3. **assert_sse_sequence(events, expected_types)**: Verify event sequence matches expected pattern
   - Check event types appear in expected order
   - Allow for heartbeat comments between events

4. **SSEEventCollector class**: Context manager for collecting SSE events with assertions
   - `events`: List of collected events
   - `text_events()`: Filter to text_delta events
   - `has_complete()`: Check if message_complete received
   - `get_usage()`: Extract usage from message_complete

Example implementation:
```python
import json
from typing import List, Dict, Any, Optional

def parse_sse_line(line: str) -> Optional[Dict[str, Any]]:
    """Parse a single SSE line into structured dict."""
    line = line.strip()
    if not line:
        return None
    if line.startswith(':'):
        # Comment (e.g., heartbeat)
        return {"comment": line[1:].strip()}
    if line.startswith('event:'):
        return {"event": line[6:].strip()}
    if line.startswith('data:'):
        data_str = line[5:].strip()
        try:
            return {"data": json.loads(data_str)}
        except json.JSONDecodeError:
            return {"data": data_str}
    return None

async def collect_sse_events(response) -> List[Dict[str, Any]]:
    """Collect all SSE events from streaming response."""
    events = []
    current_event = {}

    async for line in response.aiter_lines():
        parsed = parse_sse_line(line)
        if parsed is None:
            # Empty line = end of event
            if current_event:
                events.append(current_event)
                current_event = {}
        elif "comment" in parsed:
            events.append(parsed)
        elif "event" in parsed:
            current_event["event"] = parsed["event"]
        elif "data" in parsed:
            current_event["data"] = parsed["data"]

    # Don't forget last event if no trailing newline
    if current_event:
        events.append(current_event)

    return events

def filter_events_by_type(events: List[Dict], event_type: str) -> List[Dict]:
    """Filter events to only those matching event_type."""
    return [e for e in events if e.get("event") == event_type]

def assert_event_sequence(events: List[Dict], expected_types: List[str]):
    """Assert events contain expected types in order (ignoring heartbeats)."""
    actual_types = [e.get("event") for e in events if "event" in e]
    for expected in expected_types:
        assert expected in actual_types, f"Expected event type '{expected}' not found"
```

Also update `backend/tests/fixtures/__init__.py` to export the new helpers.
  </action>
  <verify>
```bash
cd G:\git_repos\BA_assistant\backend
python -c "from tests.fixtures.sse_helpers import collect_sse_events, parse_sse_line; print('SSE helpers imported')"
```
  </verify>
  <done>SSE helper module exists with parse_sse_line, collect_sse_events, filter_events_by_type, assert_event_sequence</done>
</task>

<task type="auto">
  <name>Task 2: Create SSE streaming unit tests</name>
  <files>backend/tests/unit/services/test_sse_streaming.py</files>
  <action>
Create `backend/tests/unit/services/test_sse_streaming.py` to test the SSE helpers and stream_with_heartbeat function.

**Class: TestSSEHelpers**
- `test_parse_sse_line_event`: Parse "event: text_delta" returns {"event": "text_delta"}
- `test_parse_sse_line_data`: Parse "data: {...}" returns {"data": parsed_dict}
- `test_parse_sse_line_comment`: Parse ": heartbeat" returns {"comment": "heartbeat"}
- `test_parse_sse_line_empty`: Parse "" returns None
- `test_filter_events_by_type`: Filter list to specific event type

**Class: TestStreamWithHeartbeat** (test the ai_service.stream_with_heartbeat function)
- `test_yields_original_events`: Events from source stream are yielded unchanged
- `test_yields_heartbeat_comments`: Heartbeat comments are valid SSE format

Note: The heartbeat timing tests are difficult to test reliably due to 1-second intervals.
Focus on format correctness rather than timing behavior.

Example tests:
```python
import pytest
from tests.fixtures.sse_helpers import (
    parse_sse_line,
    filter_events_by_type,
    assert_event_sequence,
)

class TestSSEHelpers:
    def test_parse_sse_line_event(self):
        """Event lines are parsed correctly."""
        result = parse_sse_line("event: text_delta")
        assert result == {"event": "text_delta"}

    def test_parse_sse_line_data_json(self):
        """Data lines with JSON are parsed."""
        result = parse_sse_line('data: {"text": "hello"}')
        assert result == {"data": {"text": "hello"}}

    def test_parse_sse_line_comment(self):
        """Comment lines (heartbeats) are parsed."""
        result = parse_sse_line(": heartbeat")
        assert result == {"comment": "heartbeat"}

    def test_filter_events_by_type(self):
        """Filter extracts only matching event types."""
        events = [
            {"event": "text_delta", "data": {"text": "a"}},
            {"comment": "heartbeat"},
            {"event": "text_delta", "data": {"text": "b"}},
            {"event": "message_complete", "data": {}},
        ]
        text_events = filter_events_by_type(events, "text_delta")
        assert len(text_events) == 2

    def test_assert_event_sequence(self):
        """Sequence assertion finds expected types in order."""
        events = [
            {"event": "text_delta", "data": {}},
            {"event": "message_complete", "data": {}},
        ]
        # Should not raise
        assert_event_sequence(events, ["text_delta", "message_complete"])


class TestStreamWithHeartbeat:
    @pytest.mark.asyncio
    async def test_yields_original_events(self):
        """Original events from source stream are yielded."""
        from app.services.ai_service import stream_with_heartbeat

        async def mock_source():
            yield {"event": "text_delta", "data": '{"text": "hello"}'}
            yield {"event": "message_complete", "data": "{}"}

        events = []
        async for event in stream_with_heartbeat(mock_source()):
            events.append(event)
            if event.get("event") == "message_complete":
                break

        # Should have received original events
        event_types = [e.get("event") for e in events if "event" in e]
        assert "text_delta" in event_types
        assert "message_complete" in event_types
```
  </action>
  <verify>
```bash
cd G:\git_repos\BA_assistant\backend
pytest tests/unit/services/test_sse_streaming.py -v
```
All tests pass.
  </verify>
  <done>SSE streaming tests verify helper functions and stream_with_heartbeat behavior</done>
</task>

<task type="auto">
  <name>Task 3: Expand FTS5 document search tests</name>
  <files>backend/tests/unit/services/test_document_search.py</files>
  <action>
Expand `backend/tests/unit/services/test_document_search.py` with additional test classes for comprehensive FTS5 coverage.

The file already has some tests. Add these new test classes:

**Class: TestSearchDocumentsRanking** (BM25 ranking)
- `test_higher_term_frequency_ranked_first`: Document with more matches of search term ranks higher
- `test_exact_phrase_ranked_higher`: Exact phrase match ranks higher than scattered terms
- `test_shorter_doc_with_same_matches_ranked_higher`: BM25 prefers shorter documents with same match count

**Class: TestSearchDocumentsSnippets** (highlighting)
- `test_snippet_contains_match_markers`: Result snippets contain the matching text
- `test_snippet_truncates_long_content`: Snippets are reasonably sized, not full document
- `test_multiple_matches_highlighted`: Multiple matches in same doc all marked

**Class: TestSearchDocumentsEdgeCases** (edge cases)
- `test_empty_query_returns_empty`: Empty search string returns no results
- `test_no_matches_returns_empty`: Query with no matches returns empty list
- `test_special_characters_handled`: Queries with quotes, asterisks don't crash
- `test_case_insensitive_search`: "AUTH" matches "auth" and "Auth"
- `test_partial_word_with_wildcard`: "auth*" matches "authentication", "authorize"

Example test:
```python
class TestSearchDocumentsRanking:
    """Tests for BM25 ranking in search results."""

    @pytest.mark.asyncio
    async def test_higher_term_frequency_ranked_first(self, db_session, user):
        """Documents with more occurrences of search term rank higher."""
        from app.services.document_search import index_document, search_documents

        # Create project
        project = Project(user_id=user.id, name="Test Project")
        db_session.add(project)
        await db_session.commit()

        # Document with 1 occurrence
        doc1 = Document(
            project_id=project.id,
            filename="single.md",
            content_encrypted=b"x"
        )
        # Document with 3 occurrences
        doc2 = Document(
            project_id=project.id,
            filename="triple.md",
            content_encrypted=b"x"
        )
        db_session.add_all([doc1, doc2])
        await db_session.commit()

        await index_document(db_session, doc1.id, doc1.filename, "authentication is important")
        await index_document(db_session, doc2.id, doc2.filename,
            "authentication requires authentication tokens for authentication")
        await db_session.commit()

        results = await search_documents(db_session, project.id, "authentication")

        assert len(results) == 2
        # Triple occurrence should rank first (higher BM25 score)
        assert results[0][0] == doc2.id


class TestSearchDocumentsEdgeCases:
    """Tests for edge cases and error handling."""

    @pytest.mark.asyncio
    async def test_empty_query_returns_empty(self, db_session, user):
        """Empty search query returns no results."""
        from app.services.document_search import search_documents

        project = Project(user_id=user.id, name="Test Project")
        db_session.add(project)
        await db_session.commit()

        results = await search_documents(db_session, project.id, "")
        assert results == []

    @pytest.mark.asyncio
    async def test_special_characters_handled(self, db_session, user):
        """Special characters in query don't crash search."""
        from app.services.document_search import search_documents

        project = Project(user_id=user.id, name="Test Project")
        db_session.add(project)
        await db_session.commit()

        # These should not raise exceptions
        await search_documents(db_session, project.id, '"quoted"')
        await search_documents(db_session, project.id, "test*")
        await search_documents(db_session, project.id, "test AND auth")
```

Make sure to import the user fixture from conftest (it should be available via pytest_plugins).
  </action>
  <verify>
```bash
cd G:\git_repos\BA_assistant\backend
pytest tests/unit/services/test_document_search.py -v
```
All tests pass including new ranking and edge case tests.
  </verify>
  <done>FTS5 tests cover BM25 ranking, snippet highlighting, and edge cases (empty query, special chars, case insensitivity)</done>
</task>

</tasks>

<verification>
Run all SSE and document search tests:
```bash
cd G:\git_repos\BA_assistant\backend
pytest tests/unit/services/test_sse_streaming.py tests/unit/services/test_document_search.py -v --tb=short
```

Expected: All tests pass (15+ tests across 2 files)
</verification>

<success_criteria>
- backend/tests/fixtures/sse_helpers.py exists with parse_sse_line, collect_sse_events
- test_sse_streaming.py verifies SSE helpers and stream_with_heartbeat
- test_document_search.py has TestSearchDocumentsRanking, TestSearchDocumentsEdgeCases classes
- FTS5 ranking tests verify BM25 orders by relevance
- Edge case tests verify empty query, special chars, case insensitivity
- All tests pass with `pytest tests/unit/services/test_*.py -v`
</success_criteria>

<output>
After completion, create `.planning/phases/30-backend-llm-api-tests/30-02-SUMMARY.md`
</output>
