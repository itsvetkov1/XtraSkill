---
phase: 55-frontend-display-ai-context
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/services/document_search.py
  - backend/app/services/agent_service.py
  - frontend/lib/services/ai_service.dart
  - frontend/lib/screens/conversation/widgets/source_chips.dart
autonomous: true

must_haves:
  truths:
    - "AI document_search returns results from Excel, CSV, PDF, and Word documents"
    - "AI search results are limited to top 3 chunks to prevent context window overflow"
    - "Source attribution chips show format-specific info (sheet name for Excel, page info for PDF)"
    - "Large documents do not cause context limit exceeded errors"
  artifacts:
    - path: "backend/app/services/document_search.py"
      provides: "Search with metadata, max_chunks limit, and format context in snippets"
      contains: "metadata"
    - path: "backend/app/services/agent_service.py"
      provides: "Agent tool returning format-specific metadata for source attribution"
      contains: "content_type"
    - path: "frontend/lib/services/ai_service.dart"
      provides: "DocumentSource with contentType and metadata fields"
      contains: "contentType"
    - path: "frontend/lib/screens/conversation/widgets/source_chips.dart"
      provides: "Source chips with format-specific icons and metadata labels"
      contains: "table_chart"
  key_links:
    - from: "backend/app/services/document_search.py"
      to: "backend/app/services/agent_service.py"
      via: "search_documents returns metadata tuple, agent formats for AI"
      pattern: "search_documents"
    - from: "backend/app/services/agent_service.py"
      to: "frontend/lib/services/ai_service.dart"
      via: "SSE message_complete event with documents_used containing metadata"
      pattern: "documents_used"
    - from: "frontend/lib/services/ai_service.dart"
      to: "frontend/lib/screens/conversation/widgets/source_chips.dart"
      via: "DocumentSource objects passed to SourceChips widget"
      pattern: "DocumentSource"
---

<objective>
Enhance AI document search to include metadata from all rich formats, limit retrieval to prevent context overflow, and add format-specific information to source attribution chips.

Purpose: AI needs to search and reference content from Excel/CSV/PDF/Word documents, not just text files. Source attribution must tell users which sheet or page the AI referenced. Token budget management prevents large documents from exceeding context limits.

Output: Enhanced document_search with metadata, agent service with format-specific source tracking, frontend source chips with format icons and metadata labels.
</objective>

<execution_context>
@/Users/a1testingmac/.claude/get-shit-done/workflows/execute-plan.md
@/Users/a1testingmac/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/55-frontend-display-ai-context/55-RESEARCH.md
@backend/app/services/document_search.py
@backend/app/services/agent_service.py
@frontend/lib/services/ai_service.dart
@frontend/lib/screens/conversation/widgets/source_chips.dart
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance document_search with metadata and token budget limit</name>
  <files>
    backend/app/services/document_search.py
    backend/app/services/agent_service.py
  </files>
  <action>
    **document_search.py** (`backend/app/services/document_search.py`):

    1. Update `search_documents()` to join with documents table and return content_type and metadata_json:
       ```python
       async def search_documents(
           db: AsyncSession,
           project_id: str,
           query: str,
           max_chunks: int = 3  # AI-02: Token budget — limit retrieval
       ) -> List[Tuple[str, str, str, float, str, str]]:
           """
           Search documents with metadata.

           Returns:
               List of tuples: (document_id, filename, snippet, score, content_type, metadata_json)
           """
       ```

    2. Update the SQL query to select `d.content_type` and `d.metadata_json` alongside existing columns:
       ```sql
       SELECT d.id, d.filename,
              snippet(document_fts, 2, '<mark>', '</mark>', '...', 20) as snippet,
              bm25(document_fts, 10.0, 1.0) as score,
              d.content_type,
              d.metadata_json
       FROM documents d
       JOIN document_fts fts ON d.id = fts.document_id
       WHERE d.project_id = :project_id
         AND document_fts MATCH :query
       ORDER BY score
       LIMIT :max_chunks
       ```

    3. Update the return to include all 6 elements:
       ```python
       return [(row[0], row[1], row[2], row[3], row[4], row[5]) for row in result.fetchall()]
       ```

    4. Update the LIMIT from 20 to `:max_chunks` parameter (default 3). This is the token budget mechanism — top 3 BM25-ranked chunks limit context to ~1500 tokens max.

    **agent_service.py** (`backend/app/services/agent_service.py`):

    1. Update the `search_documents_tool()` function to handle the new 6-element tuple return:
       ```python
       results = await search_documents(db, project_id, query_text)

       if not results:
           return {"content": [{"type": "text", "text": "No relevant documents found."}]}

       formatted = []
       for doc_id, filename, snippet, score, content_type, metadata_json in results[:3]:
           clean_snippet = snippet.replace("<mark>", "**").replace("</mark>", "**")

           # Add format-specific context prefix
           metadata = json.loads(metadata_json) if metadata_json else {}
           if metadata.get('sheet_names'):
               prefix = f"[Sheet: {metadata['sheet_names'][0]}] "
           elif metadata.get('page_count'):
               prefix = ""  # Page markers already in content from PDF parser
           else:
               prefix = ""

           formatted.append(f"**{filename}**: {prefix}\n{clean_snippet}")
       ```

    2. Update the documents_used tracking to include content_type and metadata:
       ```python
       try:
           docs_used = _documents_used_context.get()
           for doc_id, filename, snippet, score, content_type, metadata_json in results[:3]:
               if not any(d['id'] == doc_id for d in docs_used):
                   metadata = json.loads(metadata_json) if metadata_json else {}
                   docs_used.append({
                       'id': doc_id,
                       'filename': filename,
                       'content_type': content_type or 'text/plain',
                       'metadata': metadata,
                   })
           _documents_used_context.set(docs_used)
       except LookupError:
           pass
       ```

    3. Also update the search endpoint (routes/documents.py) to pass content_type and metadata_json in the search API response — BUT: this file is NOT in files_modified for this plan (it's owned by 55-01 wave). The search API endpoint is used for user-facing search, not AI search. The AI search goes through agent_service. So routes/documents.py's search endpoint also needs updating but is a LOW priority. If the executor has bandwidth, update it; otherwise leave for later. The critical path is agent_service -> document_search.

    **Important:** The `import json` is already at the top of agent_service.py. No new imports needed for document_search.py.
  </action>
  <verify>
    1. `grep -n 'max_chunks\|content_type\|metadata_json' backend/app/services/document_search.py` — new fields in return
    2. `grep -n 'content_type\|metadata' backend/app/services/agent_service.py | head -20` — metadata in docs_used
    3. `grep -n 'LIMIT :max_chunks\|LIMIT 3' backend/app/services/document_search.py` — token budget limit
    4. `cd backend && python -c "from app.services.document_search import search_documents; print('import ok')"` passes
  </verify>
  <done>
    document_search returns content_type and metadata_json alongside existing fields. Default limit reduced from 20 to 3 chunks for token budget. Agent service tracks content_type and metadata in documents_used for frontend source attribution.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update frontend source attribution with format-specific icons and metadata</name>
  <files>
    frontend/lib/services/ai_service.dart
    frontend/lib/screens/conversation/widgets/source_chips.dart
  </files>
  <action>
    **AI Service** (`frontend/lib/services/ai_service.dart`):

    1. Update the `DocumentSource` class to include contentType and metadata:
       ```dart
       class DocumentSource {
         final String id;
         final String filename;
         final String? contentType;
         final Map<String, dynamic>? metadata;

         DocumentSource({
           required this.id,
           required this.filename,
           this.contentType,
           this.metadata,
         });

         factory DocumentSource.fromJson(Map<String, dynamic> json) {
           return DocumentSource(
             id: json['id'] as String,
             filename: json['filename'] as String,
             contentType: json['content_type'] as String?,
             metadata: json['metadata'] as Map<String, dynamic>?,
           );
         }
       }
       ```

    2. The SSE parsing in `streamChat()` already uses `DocumentSource.fromJson()`, so the new fields will be picked up automatically from the backend's `documents_used` payload.

    **Source Chips** (`frontend/lib/screens/conversation/widgets/source_chips.dart`):

    1. Update the chip rendering to use format-specific icons:
       ```dart
       IconData _getSourceIcon(DocumentSource source) {
         final ct = source.contentType ?? 'text/plain';
         if (ct.contains('spreadsheet') || ct == 'text/csv') return Icons.table_chart;
         if (ct == 'application/pdf') return Icons.picture_as_pdf;
         if (ct.contains('wordprocessing')) return Icons.article;
         return Icons.description_outlined;
       }
       ```

    2. Update the chip label to include format-specific metadata:
       ```dart
       String _getChipLabel(DocumentSource source) {
         final name = _truncateFilename(source.filename);
         final metadata = source.metadata;
         if (metadata == null) return name;

         // Excel: show sheet name
         final sheetNames = metadata['sheet_names'] as List?;
         if (sheetNames != null && sheetNames.isNotEmpty) {
           return '$name (${sheetNames[0]})';
         }

         // PDF: show page count
         final pageCount = metadata['page_count'];
         if (pageCount != null) {
           return '$name ($pageCount pg)';
         }

         return name;
       }
       ```

    3. Update the `ActionChip` in `_buildChips()` to use `_getSourceIcon(source)` instead of hardcoded `Icons.description_outlined`, and `_getChipLabel(source)` instead of `_truncateFilename(source.filename)`.

    4. Update the tooltip to include metadata info for richer hover context.
  </action>
  <verify>
    1. `grep -n 'contentType\|content_type' frontend/lib/services/ai_service.dart` — DocumentSource has contentType
    2. `grep -n 'table_chart\|picture_as_pdf\|article' frontend/lib/screens/conversation/widgets/source_chips.dart` — format icons
    3. `grep -n 'sheet_names\|page_count' frontend/lib/screens/conversation/widgets/source_chips.dart` — metadata labels
    4. `cd frontend && flutter analyze --no-fatal-infos` passes
  </verify>
  <done>
    DocumentSource includes contentType and metadata. Source chips show format-specific icons (table for Excel, PDF icon for PDF, article for Word) and metadata labels (sheet name for Excel, page count for PDF).
  </done>
</task>

</tasks>

<verification>
1. AI document_search query returns results from Excel, CSV, PDF, and Word documents (not just text)
2. Search is limited to top 3 results (token budget — max_chunks=3)
3. Agent service tracks content_type and metadata in documents_used SSE payload
4. Frontend DocumentSource parses contentType and metadata from SSE event
5. Source attribution chips show format-specific icons (table_chart, picture_as_pdf, article)
6. Source chips show sheet name for Excel sources and page count for PDF sources
7. No "context limit exceeded" errors when searching large documents
8. `flutter analyze` and backend imports pass
</verification>

<success_criteria>
- AI can search and reference content from all 4 rich document formats
- Source attribution chips display format-specific icons matching the document type
- Excel source chips show sheet name in label (e.g., "data.xlsx (Sheet1)")
- PDF source chips show page count in label (e.g., "report.pdf (12 pg)")
- Search results limited to 3 chunks by default (token budget management)
</success_criteria>

<output>
After completion, create `.planning/phases/55-frontend-display-ai-context/55-03-SUMMARY.md`
</output>
