---
phase: 20-database-api
plan: 02
type: execute
wave: 2
depends_on: [20-01]
files_modified:
  - backend/app/services/ai_service.py
  - backend/app/routes/conversations.py
autonomous: true

must_haves:
  truths:
    - "SSE stream sends heartbeat comments every 15 seconds during LLM thinking silence"
    - "First heartbeat sent after 5 seconds of silence"
    - "Heartbeats stop when data flows and resume when silence resumes"
    - "Timeout error sent after 10 minutes of silence"
  artifacts:
    - path: "backend/app/services/ai_service.py"
      provides: "Heartbeat wrapper for streaming"
      contains: "heartbeat"
    - path: "backend/app/routes/conversations.py"
      provides: "Heartbeat-wrapped SSE stream"
      contains: "heartbeat"
  key_links:
    - from: "conversations.py event_generator"
      to: "ai_service.py stream"
      via: "Heartbeat wrapper around stream_chat"
      pattern: "(stream_with_heartbeat|heartbeat)"
---

<objective>
Implement SSE heartbeat mechanism to prevent connection timeouts during extended LLM thinking periods.

Purpose: DeepSeek and other models can take 5+ minutes for extended thinking. Without heartbeats, proxies and browsers will timeout the connection. SSE comments (`: heartbeat\n\n`) keep the connection alive without affecting the client application.

Output: Heartbeat wrapper utility that monitors streaming silence and sends periodic SSE comments, integrated into the chat endpoint.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/20-database-api/20-RESEARCH.md
@.planning/phases/20-database-api/20-CONTEXT.md
@.planning/phases/20-database-api/20-01-SUMMARY.md

@backend/app/services/ai_service.py
@backend/app/routes/conversations.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create heartbeat wrapper utility in ai_service.py</name>
  <files>backend/app/services/ai_service.py</files>
  <action>
1. **Add required imports at top of file:**
   ```python
   import asyncio
   import time
   ```
   (json import likely already present)

2. **Add heartbeat wrapper function after imports, before SYSTEM_PROMPT:**
   ```python
   async def stream_with_heartbeat(
       data_gen: AsyncGenerator[Dict[str, Any], None],
       initial_delay: float = 5.0,
       heartbeat_interval: float = 15.0,
       max_silence: float = 600.0
   ) -> AsyncGenerator[Dict[str, Any], None]:
       """
       Wrap an async generator with heartbeat comments during silence periods.

       SSE comments (format: ': heartbeat\\n\\n') are invisible to JavaScript
       EventSource clients but keep the connection alive through proxies.

       Args:
           data_gen: The source async generator yielding SSE event dicts
           initial_delay: Seconds before first heartbeat (default: 5s)
           heartbeat_interval: Seconds between subsequent heartbeats (default: 15s)
           max_silence: Maximum seconds without data before timeout error (default: 600s/10min)

       Yields:
           SSE event dicts from source generator, plus heartbeat comments during silence
       """
       queue: asyncio.Queue = asyncio.Queue()
       last_data_time = time.monotonic()
       done = False
       first_heartbeat_sent = False

       async def data_producer():
           """Forward data from source generator to queue."""
           nonlocal done
           try:
               async for item in data_gen:
                   await queue.put(("data", item))
           except Exception as e:
               await queue.put(("error", e))
           finally:
               done = True
               await queue.put(("done", None))

       async def heartbeat_producer():
           """Send heartbeat comments during silence periods."""
           nonlocal last_data_time, first_heartbeat_sent
           while not done:
               await asyncio.sleep(1)  # Check every second
               silence_duration = time.monotonic() - last_data_time

               # Check for max timeout
               if silence_duration >= max_silence:
                   await queue.put(("timeout", None))
                   return

               # Determine threshold based on whether first heartbeat sent
               threshold = initial_delay if not first_heartbeat_sent else heartbeat_interval
               if silence_duration >= threshold:
                   await queue.put(("heartbeat", None))
                   first_heartbeat_sent = True
                   last_data_time = time.monotonic()  # Reset timer after heartbeat

       # Start both producers as background tasks
       data_task = asyncio.create_task(data_producer())
       heartbeat_task = asyncio.create_task(heartbeat_producer())

       try:
           while True:
               msg_type, payload = await queue.get()

               if msg_type == "data":
                   last_data_time = time.monotonic()  # Reset on real data
                   first_heartbeat_sent = False  # Reset heartbeat delay for next silence
                   yield payload
               elif msg_type == "heartbeat":
                   # SSE comment format - sse_starlette handles the ': ' prefix
                   yield {"comment": "heartbeat"}
               elif msg_type == "timeout":
                   yield {
                       "event": "error",
                       "data": json.dumps({"message": "Timeout waiting for LLM response after 10 minutes"})
                   }
                   return
               elif msg_type == "error":
                   # Re-raise the exception
                   raise payload
               elif msg_type == "done":
                   return
       finally:
           # Clean up tasks
           data_task.cancel()
           heartbeat_task.cancel()
           try:
               await data_task
           except asyncio.CancelledError:
               pass
           try:
               await heartbeat_task
           except asyncio.CancelledError:
               pass
   ```

3. **Ensure json import exists:**
   Add `import json` at top if not already present.
  </action>
  <verify>
- `grep -n "async def stream_with_heartbeat" backend/app/services/ai_service.py` shows function exists
- `grep -n "heartbeat_interval" backend/app/services/ai_service.py` shows configurable interval
- `grep -n "max_silence" backend/app/services/ai_service.py` shows timeout configuration
- Python syntax check: `cd backend && python -c "from app.services.ai_service import stream_with_heartbeat; print('OK')"`
  </verify>
  <done>stream_with_heartbeat utility function exists with configurable timing: 5s initial delay, 15s interval, 10-min max silence timeout</done>
</task>

<task type="auto">
  <name>Task 2: Wrap chat endpoint stream with heartbeat</name>
  <files>backend/app/routes/conversations.py</files>
  <action>
1. **Update import from ai_service:**
   Change:
   ```python
   from app.services.ai_service import AIService
   ```
   To:
   ```python
   from app.services.ai_service import AIService, stream_with_heartbeat
   ```

2. **Wrap the event_generator with heartbeat:**
   In the stream_chat endpoint, the event_generator() async function yields SSE events from ai_service.stream_chat(). We need to wrap this with heartbeat support.

   The current structure is:
   ```python
   async def event_generator():
       # ... accumulation logic ...
       async for event in ai_service.stream_chat(...):
           # ... handle events ...
           yield event
       # ... post-stream logic (save message, track tokens) ...

   return EventSourceResponse(event_generator(), ...)
   ```

   **Problem:** We can't simply wrap event_generator() because it has post-stream side effects (saving messages, tracking tokens). The heartbeat wrapper should only wrap the inner stream_chat() loop.

   **Solution:** Create an inner generator for the raw stream, wrap that with heartbeat, then process in event_generator:

   Refactor stream_chat endpoint to:
   ```python
   async def event_generator():
       """Generate SSE events from AI response with heartbeat during silence."""
       accumulated_text = ""
       usage_data = None

       try:
           # Create raw stream generator
           raw_stream = ai_service.stream_chat(
               conversation,
               thread.project_id,
               thread_id,
               db
           )

           # Wrap with heartbeat for long thinking periods
           heartbeat_stream = stream_with_heartbeat(raw_stream)

           async for event in heartbeat_stream:
               # Check for client disconnect
               if await request.is_disconnected():
                   break

               # Heartbeat events pass through directly (no accumulation)
               if "comment" in event:
                   yield event
                   continue

               # Track accumulated text for saving
               if event.get("event") == "text_delta":
                   data = json.loads(event["data"])
                   accumulated_text += data.get("text", "")

               # Track usage for token tracking
               if event.get("event") == "message_complete":
                   data = json.loads(event["data"])
                   usage_data = data.get("usage", {})
                   accumulated_text = data.get("content", accumulated_text)

               yield event

           # ... rest of post-stream logic unchanged ...
   ```

   Key changes:
   - Assign `ai_service.stream_chat(...)` to `raw_stream`
   - Wrap with `stream_with_heartbeat(raw_stream)` to get `heartbeat_stream`
   - Iterate over `heartbeat_stream` instead of raw stream
   - Handle `"comment"` key in event dict (heartbeat) - yield and continue
   - All other events processed as before
  </action>
  <verify>
- `grep -n "stream_with_heartbeat" backend/app/routes/conversations.py` shows import and usage
- `grep -n "heartbeat_stream" backend/app/routes/conversations.py` shows wrapped stream
- `grep -n '"comment"' backend/app/routes/conversations.py` shows heartbeat event handling
- Backend starts without errors: `cd backend && python -c "from app.routes.conversations import router; print('OK')"`
  </verify>
  <done>Chat endpoint wraps streaming with heartbeat, handling both regular events and heartbeat comments correctly</done>
</task>

</tasks>

<verification>
1. **Heartbeat function verification:**
   - stream_with_heartbeat function exists in ai_service.py
   - Function has configurable timing parameters
   - Function yields both data events and heartbeat comments

2. **Integration verification:**
   - conversations.py imports stream_with_heartbeat
   - event_generator wraps stream with heartbeat
   - Heartbeat comments pass through to SSE response

3. **Timing verification (manual test):**
   - Send a message that triggers LLM thinking
   - If no response for 5 seconds, first heartbeat appears in network tab
   - Subsequent heartbeats every 15 seconds during silence
   - Normal streaming resumes heartbeat-free when data flows
</verification>

<success_criteria>
- [ ] stream_with_heartbeat function exists with correct signature
- [ ] Initial delay configurable (default 5s)
- [ ] Heartbeat interval configurable (default 15s)
- [ ] Max silence timeout configurable (default 600s/10min)
- [ ] Heartbeat yields {"comment": "heartbeat"} format
- [ ] Timeout yields error event with message
- [ ] conversations.py imports and uses stream_with_heartbeat
- [ ] Heartbeat events pass through event_generator correctly
- [ ] Normal events still accumulated and processed correctly
- [ ] Backend starts without import/syntax errors
</success_criteria>

<output>
After completion, create `.planning/phases/20-database-api/20-02-SUMMARY.md`
</output>
