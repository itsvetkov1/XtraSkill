---
phase: 43-backend-logging-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/config.py
  - backend/app/services/logging_service.py
  - backend/requirements.txt
autonomous: true

must_haves:
  truths:
    - "Log entries are written to rotating files in JSON format"
    - "Logging configuration is controllable via environment variables"
    - "Async operations are not blocked by file I/O"
  artifacts:
    - path: "backend/app/services/logging_service.py"
      provides: "LoggingService singleton with structlog integration"
      min_lines: 100
    - path: "backend/app/config.py"
      provides: "LOG_DIR, LOG_LEVEL, LOG_ROTATION_DAYS settings"
      contains: "log_dir"
  key_links:
    - from: "backend/app/services/logging_service.py"
      to: "backend/app/config.py"
      via: "settings import"
      pattern: "from app.config import settings"
---

<objective>
Create core LoggingService with structlog, async-safe file handlers, and configuration settings.

Purpose: Establish the logging foundation that all subsequent logging integration will build upon. The async-safe QueueHandler pattern prevents blocking the FastAPI event loop during file I/O.

Output: LoggingService singleton, updated config.py, new dependencies in requirements.txt
</objective>

<execution_context>
@C:\Users\ibcve\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\ibcve\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/SUMMARY_v1.9.5.md
@backend/app/config.py
@backend/app/services/auth_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add logging configuration to Settings</name>
  <files>backend/app/config.py</files>
  <action>
Add logging configuration fields to the Settings class in config.py:

1. Add Path import from pathlib
2. Add these fields after existing settings:
   - log_dir: str = "logs" (directory for log files, relative to backend/)
   - log_level: str = "INFO" (configurable via LOG_LEVEL env var)
   - log_rotation_days: int = 7 (how many days of logs to retain)

3. Add a property method `log_dir_path` that returns Path(log_dir) resolved relative to the backend directory

Example pattern from existing config:
```python
# Logging
log_dir: str = "logs"
log_level: str = "INFO"
log_rotation_days: int = 7

@property
def log_dir_path(self) -> Path:
    """Resolved log directory path."""
    return Path(__file__).parent.parent / self.log_dir
```

Keep imports at top, add Path to existing pathlib imports if needed.
  </action>
  <verify>
Run: python -c "from app.config import settings; print(settings.log_level, settings.log_dir_path)"
Expected: "INFO" and a path ending in "logs"
  </verify>
  <done>Config has log_dir, log_level, log_rotation_days fields accessible via settings object</done>
</task>

<task type="auto">
  <name>Task 2: Add structlog and asgi-correlation-id dependencies</name>
  <files>backend/requirements.txt</files>
  <action>
Add these dependencies to requirements.txt:

```
structlog>=25.0.0
asgi-correlation-id>=4.3.0
```

Add them after existing dependencies in the list. structlog provides structured JSON logging with processor chains. asgi-correlation-id will be used in Plan 02 for request ID propagation.

After adding, verify they can be installed without conflicts.
  </action>
  <verify>
Run: cd backend && pip install -r requirements.txt
Expected: Both packages install successfully without version conflicts
  </verify>
  <done>structlog and asgi-correlation-id are in requirements.txt and installable</done>
</task>

<task type="auto">
  <name>Task 3: Create LoggingService with async-safe file handlers</name>
  <files>backend/app/services/logging_service.py</files>
  <action>
Create LoggingService following these specifications:

1. Use structlog for structured JSON logging
2. Use stdlib logging with QueueHandler + QueueListener pattern (P-01 prevention)
3. Use TimedRotatingFileHandler for 7-day rotation
4. Create singleton pattern (like other services in the codebase)

Implementation structure:
```python
"""
Async-safe logging service with structured JSON output.

Uses QueueHandler pattern to avoid blocking the async event loop during file I/O.
Logs are written to rotating files with 7-day retention.
"""
import logging
import sys
from logging.handlers import QueueHandler, QueueListener, TimedRotatingFileHandler
from pathlib import Path
from queue import Queue
from typing import Any, Dict, Optional
import structlog
from app.config import settings


class LoggingService:
    """
    Centralized logging service with async-safe file handlers.

    Uses QueueHandler pattern: log calls go to in-memory queue,
    background thread writes to file. This prevents blocking asyncio.
    """

    _instance: Optional["LoggingService"] = None
    _initialized: bool = False

    def __new__(cls) -> "LoggingService":
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if LoggingService._initialized:
            return

        self._queue: Queue = Queue()
        self._listener: Optional[QueueListener] = None
        self._configure_logging()
        LoggingService._initialized = True

    def _configure_logging(self) -> None:
        """Set up structlog with async-safe file handler."""
        # Ensure log directory exists
        log_dir = settings.log_dir_path
        log_dir.mkdir(parents=True, exist_ok=True)

        # Create file handler with rotation
        log_file = log_dir / "app.log"
        file_handler = TimedRotatingFileHandler(
            filename=str(log_file),
            when="midnight",
            interval=1,
            backupCount=settings.log_rotation_days,
            encoding="utf-8"
        )
        file_handler.setLevel(getattr(logging, settings.log_level.upper()))

        # Create queue handler for async safety
        queue_handler = QueueHandler(self._queue)

        # Configure root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, settings.log_level.upper()))
        root_logger.addHandler(queue_handler)

        # Start queue listener in background thread
        self._listener = QueueListener(self._queue, file_handler, respect_handler_level=True)
        self._listener.start()

        # Configure structlog with JSON renderer
        structlog.configure(
            processors=[
                structlog.stdlib.filter_by_level,
                structlog.stdlib.add_logger_name,
                structlog.stdlib.add_log_level,
                structlog.stdlib.PositionalArgumentsFormatter(),
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                structlog.processors.UnicodeDecoder(),
                structlog.processors.JSONRenderer()
            ],
            wrapper_class=structlog.stdlib.BoundLogger,
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            cache_logger_on_first_use=True,
        )

    def get_logger(self, name: str = __name__) -> structlog.BoundLogger:
        """Get a bound logger instance."""
        return structlog.get_logger(name)

    def log(
        self,
        level: str,
        message: str,
        category: str,
        correlation_id: Optional[str] = None,
        **data: Any
    ) -> None:
        """
        Log a structured message.

        Args:
            level: Log level (DEBUG, INFO, WARNING, ERROR)
            message: Human-readable message
            category: Log category (api, ai, db, etc.)
            correlation_id: Request correlation ID
            **data: Additional structured data
        """
        logger = self.get_logger()
        log_data: Dict[str, Any] = {
            "category": category,
            "message": message,
        }
        if correlation_id:
            log_data["correlationId"] = correlation_id
        log_data.update(data)

        log_method = getattr(logger, level.lower(), logger.info)
        log_method(**log_data)

    def shutdown(self) -> None:
        """Stop the queue listener cleanly."""
        if self._listener:
            self._listener.stop()


# Module-level singleton for easy import
_logging_service: Optional[LoggingService] = None


def get_logging_service() -> LoggingService:
    """Get the singleton LoggingService instance."""
    global _logging_service
    if _logging_service is None:
        _logging_service = LoggingService()
    return _logging_service
```

Key points:
- QueueHandler pattern (P-01): Log calls go to queue, background thread writes to file
- TimedRotatingFileHandler: Rotates at midnight, keeps log_rotation_days backups
- structlog.processors.JSONRenderer(): Produces JSON output
- Singleton pattern: Same as other services in codebase
- Category field: Enables filtering (api, ai, db)
  </action>
  <verify>
Run in backend directory:
```bash
cd backend && python -c "
from app.services.logging_service import get_logging_service
ls = get_logging_service()
ls.log('INFO', 'Test message', 'test', data={'key': 'value'})
import os
print('Log file exists:', os.path.exists('logs/app.log'))
with open('logs/app.log') as f:
    print('Last line:', f.readlines()[-1])
ls.shutdown()
"
```
Expected: Log file exists with JSON-formatted entry containing category, message, timestamp
  </verify>
  <done>LoggingService writes JSON logs to rotating file via async-safe queue</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify config settings:
   ```bash
   cd backend && python -c "from app.config import settings; print(settings.log_level, settings.log_dir, settings.log_rotation_days)"
   ```
   Expected: INFO logs 7

2. Verify JSON log format:
   ```bash
   cd backend && python -c "
   from app.services.logging_service import get_logging_service
   ls = get_logging_service()
   ls.log('INFO', 'Verification test', 'api', correlation_id='test-123', endpoint='/test')
   ls.shutdown()
   import json
   with open('logs/app.log') as f:
       entry = json.loads(f.readlines()[-1])
       assert 'timestamp' in entry
       assert entry['category'] == 'api'
       assert entry['correlationId'] == 'test-123'
       print('JSON schema valid')
   "
   ```

3. Verify requirements install:
   ```bash
   cd backend && pip install -r requirements.txt && python -c "import structlog; print('structlog:', structlog.__version__)"
   ```
</verification>

<success_criteria>
- Config has LOG_DIR, LOG_LEVEL, LOG_ROTATION_DAYS settings (env-configurable)
- LoggingService singleton creates logs/app.log with JSON entries
- QueueHandler pattern prevents blocking (queue + background listener)
- structlog and asgi-correlation-id in requirements.txt
</success_criteria>

<output>
After completion, create `.planning/phases/43-backend-logging-foundation/43-01-SUMMARY.md`
</output>
