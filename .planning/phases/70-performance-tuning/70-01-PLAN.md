---
phase: 70-performance-tuning
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/services/llm/claude_cli_adapter.py
  - backend/main.py
  - backend/tests/unit/llm/test_claude_process_pool.py
autonomous: true
requirements:
  - PERF-01
  - PERF-02
  - PERF-03

must_haves:
  truths:
    - "Subprocess cold-start latency is measured via time.perf_counter() and logged on every stream_chat() call"
    - "Pre-warmed processes are acquired from an asyncio.Queue instead of spawning cold on each request"
    - "When pool is empty, stream_chat() falls back to cold spawn transparently (no user-visible error)"
    - "Pool processes are cleanly terminated on FastAPI app shutdown"
    - "Warm vs cold latency difference is documented in code comments and test assertions"
  artifacts:
    - path: "backend/app/services/llm/claude_cli_adapter.py"
      provides: "ClaudeProcessPool class + pool integration in stream_chat()"
      contains: "class ClaudeProcessPool"
    - path: "backend/main.py"
      provides: "Pool startup/shutdown in FastAPI lifespan"
      contains: "process_pool"
    - path: "backend/tests/unit/llm/test_claude_process_pool.py"
      provides: "Unit tests for pool acquire, cold fallback, dead process, start/stop, latency logging"
      min_lines: 80
  key_links:
    - from: "backend/app/services/llm/claude_cli_adapter.py"
      to: "backend/main.py"
      via: "get_process_pool() singleton accessed in lifespan startup/shutdown"
      pattern: "get_process_pool"
    - from: "backend/app/services/llm/claude_cli_adapter.py (stream_chat)"
      to: "ClaudeProcessPool.acquire()"
      via: "pool.acquire() replaces direct asyncio.create_subprocess_exec()"
      pattern: "pool\\.acquire\\(\\)"
---

<objective>
Implement a pre-warming subprocess pool for ClaudeCLIAdapter that eliminates cold-start spawn overhead on each chat message.

Purpose: Each Assistant message currently spawns a fresh `claude -p` subprocess, paying ~120-400ms of CLI startup time. A pre-warming pool keeps warm processes ready in an asyncio.Queue, reducing per-message spawn overhead to near-zero. This is the final phase of v3.1.1 milestone.

Output:
- `ClaudeProcessPool` class with asyncio.Queue-based pre-warming, cold fallback, and clean shutdown
- `stream_chat()` integration using pool.acquire() instead of direct subprocess spawn
- FastAPI lifespan hooks for pool startup/shutdown
- Latency measurement logging on every acquire (cold vs warm)
- Unit tests covering pool behavior and latency documentation
</objective>

<execution_context>
@/Users/a1testingmac/.claude/get-shit-done/workflows/execute-plan.md
@/Users/a1testingmac/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/70-performance-tuning/70-RESEARCH.md
@backend/app/services/llm/claude_cli_adapter.py
@backend/main.py
@backend/tests/unit/llm/test_claude_cli_adapter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ClaudeProcessPool and integrate into stream_chat()</name>
  <files>backend/app/services/llm/claude_cli_adapter.py</files>
  <action>
Add a `ClaudeProcessPool` class to `claude_cli_adapter.py` (same file — keep pool near its sole consumer). The class implements an asyncio.Queue-based pre-warming pool:

**ClaudeProcessPool class (add above ClaudeCLIAdapter):**
- `POOL_SIZE = 2` class constant (sufficient for single-user dev context)
- `REFILL_DELAY = 0.1` seconds between refill checks
- `__init__(self, cli_path: str, model: str)` — stores cli_path, model; creates `asyncio.Queue(maxsize=POOL_SIZE)`; sets `_running = False`
- `async start(self) -> None` — sets `_running = True`, pre-spawns POOL_SIZE processes via `_spawn_warm_process()`, puts them in queue, starts `_refill_loop()` as background task
- `async stop(self) -> None` — sets `_running = False`, cancels refill task, drains queue and terminates all remaining processes (terminate → wait(2s) → kill if timeout)
- `async acquire(self) -> asyncio.subprocess.Process` — tries `_queue.get_nowait()`, checks `proc.returncode is None` (alive check), falls back to `_cold_spawn()` if pool empty or process dead
- `async _spawn_warm_process(self) -> Optional[asyncio.subprocess.Process]` — spawns `claude -p --output-format stream-json --verbose --model {model}` with stdin/stdout/stderr PIPE, env filtered (strip CLAUDECODE/CLAUDE_CODE_ENTRYPOINT), limit=1MB. Returns None on failure (log warning).
- `async _cold_spawn(self) -> asyncio.subprocess.Process` — same as _spawn_warm_process but raises on failure (no fallback)
- `async _refill_loop(self) -> None` — while _running, sleep REFILL_DELAY, then spawn processes until queue.qsize() reaches POOL_SIZE. Handle QueueFull by terminating excess process.

**Important:** The env dictionary construction (filtering CLAUDECODE/CLAUDE_CODE_ENTRYPOINT) should be shared between the pool's _spawn methods and stream_chat(). Extract it to a module-level helper `_build_cli_env() -> dict`.

**Module-level singleton and accessor:**
```python
_process_pool: Optional[ClaudeProcessPool] = None

def get_process_pool() -> Optional[ClaudeProcessPool]:
    return _process_pool

async def init_process_pool(cli_path: str, model: str) -> ClaudeProcessPool:
    global _process_pool
    pool = ClaudeProcessPool(cli_path=cli_path, model=model)
    await pool.start()
    _process_pool = pool
    return pool

async def shutdown_process_pool() -> None:
    global _process_pool
    if _process_pool:
        await _process_pool.stop()
        _process_pool = None
```

**Integrate pool into `ClaudeCLIAdapter.stream_chat()`:**
1. Import `time` at module top (for perf_counter)
2. After building `cmd` and `env`, instead of calling `asyncio.create_subprocess_exec(*cmd, ...)` directly:
   - Try `pool = get_process_pool()`
   - If pool is not None: `acquire_start = time.perf_counter()` → `process = await pool.acquire()` → calculate `acquire_ms` → log `f"Process acquired from pool in {acquire_ms:.1f}ms (queue_size={pool._queue.qsize()})"`
   - If pool is None (not initialized): cold-spawn directly as before, log warning "Process pool not initialized, using cold spawn"
3. The prompt writing (stdin.write, drain, close) and stdout reading loop remain unchanged.

**Latency documentation (PERF-01, PERF-03):**
Add a docstring block to ClaudeProcessPool documenting:
```
Latency improvement:
  Cold start (no pool): ~120-400ms (OS spawn + Node.js init + auth check)
  Warm acquire (pool):  <5ms (asyncio.Queue.get_nowait)
  Measured baseline:    See test_claude_process_pool.py
```

**Anti-patterns to avoid (from research):**
- Do NOT use `--input-format stream-json` (known bugs, Issue #5034)
- Do NOT use `--continue` or `--session-id` (active bugs, incompatible with --print)
- Do NOT block on queue.get() — use get_nowait() with cold fallback
- Do NOT share processes across requests — each `claude -p` is single-shot
  </action>
  <verify>
Run existing CLI adapter tests to confirm no regressions:
```bash
cd backend && ./venv/bin/python -m pytest tests/unit/llm/test_claude_cli_adapter.py -q
```
Expected: 49 passing, 1 pre-existing fail (test_stream_chat_passes_api_key_in_env). No new failures.
  </verify>
  <done>
ClaudeProcessPool class exists in claude_cli_adapter.py with start/stop/acquire methods. stream_chat() uses pool.acquire() when pool is available, falls back to cold spawn when not. Latency is logged via time.perf_counter() on every acquire. Module-level singleton functions (get_process_pool, init_process_pool, shutdown_process_pool) are exported.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire pool into FastAPI lifespan and add unit tests</name>
  <files>
    backend/main.py
    backend/tests/unit/llm/test_claude_process_pool.py
  </files>
  <action>
**Part A: FastAPI lifespan integration (backend/main.py):**

In the `lifespan()` async context manager, add pool initialization after database init and pool shutdown before database close:

```python
# In startup section (after init_db):
import shutil
from app.services.llm.claude_cli_adapter import init_process_pool, shutdown_process_pool

# Only initialize pool if Claude CLI is available
cli_path = shutil.which("claude")
if cli_path:
    from app.services.llm.claude_cli_adapter import DEFAULT_MODEL
    await init_process_pool(cli_path=cli_path, model=DEFAULT_MODEL)
    print("Claude CLI process pool initialized")
else:
    print("Claude CLI not found, process pool not initialized")

# In shutdown section (before close_db):
await shutdown_process_pool()
print("Claude CLI process pool shutdown")
```

The pool init is conditional on CLI availability — if claude is not installed, the pool is simply not created, and stream_chat() falls back to cold spawn (which will fail with the existing RuntimeError from __init__).

**Part B: Unit tests (backend/tests/unit/llm/test_claude_process_pool.py):**

Create a new test file with the following test cases using pytest-asyncio and unittest.mock:

1. **test_warm_acquire_returns_queued_process** — Pre-fill queue with a mock process (returncode=None). Call acquire(). Assert the mock process is returned and create_subprocess_exec was NOT called. (PERF-02: warm reuse works)

2. **test_cold_fallback_when_pool_empty** — Leave queue empty. Patch create_subprocess_exec. Call acquire(). Assert create_subprocess_exec was called once. (PERF-02: fallback works)

3. **test_dead_process_triggers_cold_spawn** — Put a mock process with returncode=1 (dead) in queue. Patch create_subprocess_exec. Call acquire(). Assert cold spawn was triggered. (PERF-02: health check)

4. **test_start_prewarms_pool** — Patch create_subprocess_exec to return mock processes. Call pool.start(). Assert queue.qsize() == POOL_SIZE. Cancel refill task. (PERF-02: pre-warming)

5. **test_stop_terminates_remaining_processes** — Put 2 mock processes in queue. Call pool.stop(). Assert terminate() was called on both. (PERF-02: clean shutdown)

6. **test_acquire_latency_logged** — Patch logger and pool queue. Call stream_chat() with pool initialized. Assert log message contains "Process acquired" and "ms". (PERF-01: latency measured)

7. **test_pool_not_initialized_falls_back_to_cold_spawn** — Ensure get_process_pool() returns None. Verify stream_chat() still works by spawning directly. (PERF-02: graceful degradation)

8. **test_latency_documentation_exists** — Assert ClaudeProcessPool.__doc__ contains "Cold start" and "Warm acquire" and latency numbers. (PERF-03: documented)

**Mock patterns (from existing test_claude_cli_adapter.py):**
- Use `@patch('app.services.llm.claude_cli_adapter.asyncio.create_subprocess_exec')` for subprocess mocking
- Use `MagicMock()` for process objects with configurable `returncode`, `terminate()`, `wait()`, `stdin`, `stdout`, `stderr`
- Use `@pytest.mark.asyncio` for all async tests
- Import from `app.services.llm.claude_cli_adapter` (not relative)

**Test baseline verification:**
The file header should document: "Test baseline: 49 existing + 1 pre-existing fail in test_claude_cli_adapter.py"
  </action>
  <verify>
Run all pool tests:
```bash
cd backend && ./venv/bin/python -m pytest tests/unit/llm/test_claude_process_pool.py -v
```
Expected: All 8 tests pass.

Run full LLM test suite to confirm no regressions:
```bash
cd backend && ./venv/bin/python -m pytest tests/unit/llm/ -q
```
Expected: 49 + 8 = 57 passing, 1 pre-existing fail (unchanged).
  </verify>
  <done>
FastAPI lifespan initializes pool on startup (conditional on CLI availability) and shuts it down on shutdown. 8 unit tests cover warm acquire, cold fallback, dead process handling, pre-warming, shutdown, latency logging, graceful degradation, and documentation existence. All tests pass. Pre-existing test failure unchanged.
  </done>
</task>

</tasks>

<verification>
1. **PERF-01 (Baseline measured):** `time.perf_counter()` wraps every `pool.acquire()` call in `stream_chat()`, logging acquire latency in milliseconds. Test `test_acquire_latency_logged` verifies the measurement exists.

2. **PERF-02 (Process pooling):** `ClaudeProcessPool` with asyncio.Queue pre-warms POOL_SIZE=2 processes at startup. `stream_chat()` acquires from pool instead of cold-spawning. Tests verify warm acquire, cold fallback, dead process detection, pre-warming, and clean shutdown.

3. **PERF-03 (Improvement documented):** ClaudeProcessPool docstring documents cold start (~120-400ms) vs warm acquire (<5ms) latency. Test `test_latency_documentation_exists` asserts documentation is present.

4. **No regressions:** Existing 49 tests in test_claude_cli_adapter.py continue to pass. Pre-existing test_stream_chat_passes_api_key_in_env failure remains at 1.

**Full verification command:**
```bash
cd backend && ./venv/bin/python -m pytest tests/unit/llm/ -v --tb=short
```
Expected: 57 passing, 1 failing (pre-existing).
</verification>

<success_criteria>
- ClaudeProcessPool class exists with start/stop/acquire methods
- stream_chat() uses pool.acquire() with cold fallback when pool unavailable
- FastAPI lifespan manages pool lifecycle (conditional on CLI availability)
- Latency logged on every acquire call via time.perf_counter()
- 8 new unit tests all pass
- 49 existing CLI adapter tests still pass (1 pre-existing fail unchanged)
- Pool docstring documents cold vs warm latency numbers
</success_criteria>

<output>
After completion, create `.planning/phases/70-performance-tuning/70-01-SUMMARY.md`
</output>
